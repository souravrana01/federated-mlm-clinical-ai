
# Day 5: ClinicalBERT + MedNLI Data Processing (Google Colab Ready)

# Step 1: Install necessary libraries
!pip install transformers torch

# Step 2: Import required libraries
import torch
from transformers import AutoTokenizer
import json

# Step 3: Load and preview the uploaded JSONL MedNLI data
uploaded_file = 'mednli_train.jsonl'  # Ensure this file is uploaded in Colab
examples = []

with open(uploaded_file, 'r') as f:
    for line in f:
        entry = json.loads(line)
        if entry['gold_label'] in ['entailment', 'neutral', 'contradiction']:
            examples.append(entry)

print(f"Loaded {len(examples)} examples")

# Step 4: Tokenize with ClinicalBERT
tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")

sentence1_list = [ex['sentence1'] for ex in examples]
sentence2_list = [ex['sentence2'] for ex in examples]
labels = [ex['gold_label'] for ex in examples]

label_map = {'entailment': 0, 'neutral': 1, 'contradiction': 2}
mapped_labels = [label_map[label] for label in labels]

tokens = tokenizer(sentence1_list, sentence2_list,
                   padding=True, truncation=True, max_length=128, return_tensors="pt")

print("âœ… Tokenization complete and data ready.")
